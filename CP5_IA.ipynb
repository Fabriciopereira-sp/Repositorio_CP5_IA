{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ac8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Projeto: Predição de Doenças Cardíacas (Pipeline Completo com ML)\n",
    "# Nome e RM: [Fabrício Henrique Pereira, RM 563237]\n",
    "# Descrição: Implementação de um pipeline de classificação supervisionada\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "from typing import Tuple, Dict, Any, List\n",
    "\n",
    "# Bibliotecas de Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    ")\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURAÇÕES GERAIS E LOGGING\n",
    "# ==============================================================================\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Configura o sistema de log para registrar as etapas importantes\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "# Constantes para garantir a reprodutibilidade\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.3\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Dados do Dataset\n",
    "URL_DATASET = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data'\n",
    "COLUMN_NAMES = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
    "    'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'\n",
    "]\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# FUNÇÕES AUXILIARES DE AVALIAÇÃO\n",
    "# ==============================================================================\n",
    "\n",
    "def avaliar_modelo(y_true: pd.Series, y_pred: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"Calcula e retorna as métricas de classificação chave.\"\"\"\n",
    "    return {\n",
    "        'Acurácia': accuracy_score(y_true, y_pred),\n",
    "        'Precisão': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'F1-Score': f1_score(y_true, y_pred, zero_division=0)\n",
    "    }\n",
    "\n",
    "def plotar_matriz_confusao(y_true: pd.Series, y_pred: np.ndarray, nome: str, cmap: str = 'Blues'):\n",
    "    \"\"\"Plota a Matriz de Confusão para visualização no Notebook.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=['Sem Doença (0)', 'Com Doença (1)'])\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    disp.plot(cmap=cmap, ax=ax)\n",
    "    plt.title(f'Matriz de Confusão - {nome}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# FUNÇÕES PRINCIPAIS DO PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "def preparar_dados(url: str, names: List[str], test_size: float, rs: int) -> Tuple[ColumnTransformer, pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"Carrega, limpa e divide o dataset. Retorna o pré-processador e os dados.\"\"\"\n",
    "    logging.info(\"--- ETAPA 1: Carregamento e Pré-processamento ---\")\n",
    "\n",
    "    # 1. Carregamento e Limpeza Inicial\n",
    "    df = pd.read_csv(url, header=None, names=names)\n",
    "    logging.info(f\"Dados brutos carregados: {len(df)} registros.\")\n",
    "    \n",
    "    # Tratamento de valores desconhecidos e ausentes\n",
    "    df.replace('?', np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Conversão de tipos e Definição do Alvo Binário\n",
    "    df['ca'] = pd.to_numeric(df['ca'])\n",
    "    df['thal'] = pd.to_numeric(df['thal'])\n",
    "    df['target'] = df['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    logging.info(f\"Dados limpos: {len(df)} registros.\")\n",
    "    logging.info(f\"Distribuição da classe alvo:\\n{df['target'].value_counts(normalize=True)}\")\n",
    "\n",
    "    # 2. Divisão e Feature Engineering\n",
    "    X = df.drop('target', axis=1)\n",
    "    y = df['target']\n",
    "\n",
    "    # Divisão com estratificação para manter a proporção da classe alvo\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=rs, stratify=y\n",
    "    )\n",
    "\n",
    "    # Definição das colunas para o ColumnTransformer\n",
    "    num_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "    cat_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "\n",
    "    # ColumnTransformer: Aplica transformações distintas para diferentes tipos de variáveis\n",
    "    preprocessor = ColumnTransformer([\n",
    "        # Padronização para modelos sensíveis à escala (LogReg, KNN)\n",
    "        ('scaler', StandardScaler(), num_features),\n",
    "        # Codificação One-Hot para variáveis categóricas\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_features)\n",
    "    ], remainder='passthrough')\n",
    "    \n",
    "    logging.info(\"Pré-processador (ColumnTransformer) definido com sucesso.\")\n",
    "    return preprocessor, X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def treinar_modelos_base(preprocessor: ColumnTransformer, X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.Series, y_test: pd.Series):\n",
    "    \"\"\"Treina os 3 modelos base e identifica o vencedor.\"\"\"\n",
    "    logging.info(\"\\n--- ETAPA 2: Treinamento e Avaliação dos Modelos Base (3) ---\")\n",
    "\n",
    "    modelos = {\n",
    "        \"Regressão Logística\": LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=100)\n",
    "    }\n",
    "\n",
    "    resultados = {}\n",
    "    metricas = pd.DataFrame(columns=['Acurácia', 'Precisão', 'Recall', 'F1-Score', 'Tempo (s)'])\n",
    "\n",
    "    for nome, modelo in modelos.items():\n",
    "        inicio = time.time()\n",
    "        # Pipeline: Combina o pré-processamento com o classificador\n",
    "        pipe = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', modelo)])\n",
    "        \n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        fim = time.time()\n",
    "\n",
    "        # Avaliação\n",
    "        m = avaliar_modelo(y_test, y_pred)\n",
    "        m['Tempo (s)'] = fim - inicio\n",
    "        metricas.loc[nome] = m\n",
    "        resultados[nome] = pipe\n",
    "\n",
    "        logging.info(f\"  {nome} treinado | F1: {m['F1-Score']:.4f} | Tempo: {m['Tempo (s)']:.2f}s\")\n",
    "        plotar_matriz_confusao(y_test, y_pred, nome) # Plota para visualização no Notebook\n",
    "\n",
    "    metricas = metricas.sort_values(by='F1-Score', ascending=False)\n",
    "    melhor_nome = metricas.index[0]\n",
    "    melhor_modelo = resultados[melhor_nome]\n",
    "\n",
    "    print(\"\\n--- Tabela Comparativa de Métricas (Modelos Base) ---\")\n",
    "    print(metricas.to_markdown(floatfmt=\".4f\"))\n",
    "    logging.info(f\"\\nModelo Base Vencedor (F1-Score): {melhor_nome}\")\n",
    "    \n",
    "    return melhor_modelo, melhor_nome, metricas\n",
    "\n",
    "\n",
    "def otimizar_modelo(modelo_base: Pipeline, nome_modelo: str, X_train: pd.DataFrame, y_train: pd.Series, scoring: str = 'f1') -> Pipeline:\n",
    "    \"\"\"Otimiza o modelo vencedor utilizando busca em grade (GridSearchCV).\"\"\"\n",
    "    logging.info(f\"\\n--- ETAPA 3: Otimização de Hiperparâmetros ({nome_modelo}) ---\")\n",
    "\n",
    "    # Hiperparâmetros a serem testados (Foco no modelo que geralmente ganha)\n",
    "    grids = {\n",
    "        \"Random Forest\": {\n",
    "            'classifier__n_estimators': [100, 200, 300], # Quantidade de árvores\n",
    "            'classifier__max_depth': [5, 10, 15, None],   # Profundidade máxima\n",
    "            'classifier__min_samples_split': [2, 5, 10]  # Mínimo para divisão\n",
    "        },\n",
    "        \"KNN\": {\n",
    "            'classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
    "            'classifier__weights': ['uniform', 'distance']\n",
    "        },\n",
    "        \"Regressão Logística\": {\n",
    "            'classifier__C': [0.01, 0.1, 1.0, 10.0],\n",
    "            'classifier__penalty': ['l2'] # Usando L2 que é o padrão com 'newton-cg', 'lbfgs', 'sag', 'saga'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        param_grid = grids[nome_modelo]\n",
    "    except KeyError:\n",
    "        logging.warning(\"Grid de hiperparâmetros não definido para este modelo. Retornando modelo base.\")\n",
    "        return modelo_base\n",
    "\n",
    "    # GridSearchCV: Busca exaustiva com Cross-Validation (CV=5)\n",
    "    search = GridSearchCV(\n",
    "        modelo_base, param_grid, cv=5, scoring=scoring, n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    inicio = time.time()\n",
    "    search.fit(X_train, y_train)\n",
    "    fim = time.time()\n",
    "\n",
    "    logging.info(f\"Otimização concluída em {fim - inicio:.2f}s.\")\n",
    "    logging.info(f\"Melhores parâmetros encontrados: {search.best_params_}\")\n",
    "    \n",
    "    return search.best_estimator_ # Retorna o melhor Pipeline encontrado\n",
    "\n",
    "\n",
    "def avaliar_final(modelo_otimizado: Pipeline, X_test: pd.DataFrame, y_test: pd.Series, nome_modelo: str, metricas_base: pd.DataFrame):\n",
    "    \"\"\"Compara o modelo otimizado com o base e gera o relatório final.\"\"\"\n",
    "    logging.info(f\"\\n--- ETAPA 4: Avaliação Final do Modelo Otimizado ({nome_modelo}) ---\")\n",
    "    \n",
    "    y_pred = modelo_otimizado.predict(X_test)\n",
    "    m_final = avaliar_modelo(y_test, y_pred)\n",
    "    f1_base = metricas_base.loc[nome_modelo]['F1-Score']\n",
    "\n",
    "    # Relatório de Classificação Detalhado\n",
    "    print(\"\\nRelatório de Classificação (Precision, Recall, F1-Score por classe):\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    \n",
    "    # Análise de Melhoria\n",
    "    melhoria = (m_final['F1-Score'] - f1_base) / f1_base * 100 if f1_base != 0 else 0\n",
    "    \n",
    "    print(\"\\n--- Sumário de Métricas Finais ---\")\n",
    "    print(f\"F1-Score Base: {f1_base:.4f}\")\n",
    "    print(f\"F1-Score Otimizado: {m_final['F1-Score']:.4f}\")\n",
    "    print(f\"Melhoria no F1-Score: {melhoria:.2f}%\")\n",
    "\n",
    "    # Visualização da Matriz de Confusão Final\n",
    "    plotar_matriz_confusao(y_test, y_pred, f'{nome_modelo} Otimizado', cmap='Greens')\n",
    "    \n",
    "    logging.info(\"Projeto concluído. Resultados disponíveis no Notebook.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# MAIN \n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.info(\"Iniciando Pipeline Completo de Predição de Doenças Cardíacas (CP5)\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 1. Pré-processamento\n",
    "    preprocessor, X_train, X_test, y_train, y_test = preparar_dados(\n",
    "        URL_DATASET, COLUMN_NAMES, TEST_SIZE, RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    # 2. Treinamento e Escolha do Melhor Modelo Base\n",
    "    best_pipe, best_name, base_metrics = treinar_modelos_base(\n",
    "        preprocessor, X_train, X_test, y_train, y_test\n",
    "    )\n",
    "    \n",
    "    # 3. Otimização \n",
    "    optimized_pipe = otimizar_modelo(\n",
    "        best_pipe, best_name, X_train, y_train\n",
    "    )\n",
    "    \n",
    "    # Avaliação Final e Conclusão\n",
    "    avaliar_final(\n",
    "        optimized_pipe, X_test, y_test, best_name, base_metrics\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
